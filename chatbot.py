import os
import time
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_mistralai.chat_models import ChatMistralAI
from langchain_mistralai import MistralAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI



# 1. Configurer votre cl√© API Mistral
api_key = os.getenv('MISTRAL_AI_KEY')

# 2. Charger les embeddings Mistral
embeddings = MistralAIEmbeddings(model="mistral-embed", api_key=api_key)

# 3. Charger la base vectorielle FAISS
vectorstore = FAISS.load_local(
    "faiss_index", 
    embeddings, 
    allow_dangerous_deserialization=True  # n√©cessaire car on utilise pickle
)

# 4. Charger le mod√®le de chat Mistral
llm = ChatMistralAI(model="mistral-small", api_key=api_key)

# 5. D√©finir le prompt avec context et question
prompt_template = PromptTemplate.from_template("""
Tu es un assistant culturel sp√©cialis√© dans les √©v√©nements en r√©gion Occitanie.

En te basant sur les informations suivantes, propose des recommandations d'√©v√©nements pertinentes √† l'utilisateur.

Contexte : 
{context}

Question de l'utilisateur : 
{question}

Si tu ne trouves pas d'√©v√©nement correspondant, informe l'utilisateur de mani√®re courtoise.
""")

# 6. Construire la cha√Æne QA avec r√©cup√©ration via FAISS
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(),
    chain_type_kwargs={
        "prompt": prompt_template,
        "document_variable_name": "context"  # üëà Obligatoire pour injecter le contexte dans le prompt
    }
)

# 7. Boucle de chat
print("ü§ñ Bienvenue dans le chatbot culturel Occitanie ! Posez votre question (ou tapez 'exit' pour quitter)\n")

while True:
    user_input = input("Vous : ")
    if user_input.lower() in ["exit", "quit", "q"]:
        print("üëã √Ä bient√¥t !")
        break

    try:
        response = qa_chain.invoke({"query": user_input})
        context = response.get("result", "").strip()  # R√©cup√®re le contexte des r√©sultats

        # V√©rification du contexte avant d'afficher
        if not context or "aucun √©v√©nement" in context.lower():
            print("‚ùå D√©sol√©, je n'ai trouv√© aucun √©v√©nement correspondant √† votre recherche.")
        else:
            print(f"\nAssistant : {context}\n")
    except Exception as e:
        # Gestion des erreurs (par exemple, 429 pour trop de requ√™tes envoy√©es)
        if "429" in str(e):
            print("üö¶ Trop de requ√™tes envoy√©es √† l'API Mistral. Attendez quelques secondes et r√©essayez.")
            time.sleep(5)  # Attente de 5 secondes avant de r√©essayer
        else:
            print("‚ùå Une erreur est survenue :", e)
