import os
import pickle
from langchain_community.vectorstores import FAISS
from langchain_mistralai import MistralAIEmbeddings
from Openagenda import (
    obtenir_evenements_structures,
    generer_documents,
    decouper_documents,
)

load_dotenv()
api_key = os.getenv('MISTRAL_AI_KEY')

now = datetime.now(timezone.utc)
print("Date actuelle:", now)

# â€” Ã‰tape 1 : Charger les Ã©vÃ©nements
print(" RÃ©cupÃ©ration des Ã©vÃ©nements...")
df_events = obtenir_evenements_structures()
df_events["lastdate_end"] = pd.to_datetime(df_events["lastdate_end"], errors="coerce", utc=True)
df_events["firstdate_begin"] = pd.to_datetime(df_events["firstdate_begin"], errors="coerce", utc=True)

print(" Filtrage des Ã©vÃ©nements...")
df_events = df_events[
    (df_events["lastdate_end"] >= now) &
    (df_events["description_fr"].notnull()) &
    (df_events["title_fr"].notnull())
]

# â€” Ã‰tape 2 : Convertir en documents Langchain
print(" Conversion en objets Documents...")
documents = generer_documents(df_events)


# â€” Ã‰tape 3 : DÃ©coupage sÃ©mantique
print("âœ‚ DÃ©coupage sÃ©mantique des documents...")
docs_chunked = decouper_documents(documents)

# â€” Ã‰tape 4 : Initialiser les embeddings
print(" GÃ©nÃ©ration des embeddings (Mistral)...")
embeddings = MistralAIEmbeddings(model="mistral-embed", api_key=api_key)

# â€” Ã‰tape 5 : Indexation dans FAISS
print(" Indexation FAISS...")
vectorstore = FAISS.from_documents(docs_chunked, embeddings)

# â€” Ã‰tape 6 : Sauvegarde
print(" Sauvegarde locale de l'index FAISS...")
vectorstore.save_local("faiss_index")

# â€” Ã‰tape 7 : Test
query = "Ã©vÃ©nements de jazz Ã  Toulouse"
print(f"ğŸ” Recherche sÃ©mantique : {query}")
docs_retrieved = vectorstore.similarity_search(query, k=3)

for i, doc in enumerate(docs_retrieved, 1):
    print(f"\n RÃ©sultat {i}:")
    print(doc.page_content)
    print(" MÃ©tadonnÃ©es:", doc.metadata)
