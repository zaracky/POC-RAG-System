import os
import pickle
from langchain_community.vectorstores import FAISS
from langchain_mistralai import MistralAIEmbeddings
from Openagenda import (
    obtenir_evenements_structures,
    generer_documents,
    decouper_documents,
)

load_dotenv()
api_key = os.getenv('MISTRAL_AI_KEY')

# â€” Ã‰tape 1 : Charger les Ã©vÃ©nements
print("ğŸ“¥ RÃ©cupÃ©ration des Ã©vÃ©nements...")
df_events = obtenir_evenements_structures()

# â€” Ã‰tape 2 : Convertir en documents Langchain
print("ğŸ§± Conversion en objets Documents...")
documents = generer_documents(df_events)

# â€” Ã‰tape 3 : DÃ©coupage sÃ©mantique
print("âœ‚ï¸ DÃ©coupage sÃ©mantique des documents...")
docs_chunked = decouper_documents(documents)

# â€” Ã‰tape 4 : Initialiser les embeddings
print("ğŸ” GÃ©nÃ©ration des embeddings...")
embeddings = MistralAIEmbeddings(model="mistral-embed", api_key=api_key)

# â€” Ã‰tape 5 : Indexation dans FAISS
print("ğŸ“¦ Indexation FAISS...")
vectorstore = FAISS.from_documents(docs_chunked, embeddings)

# â€” Ã‰tape 6 : Sauvegarde (optionnelle mais conseillÃ©e)
print("ğŸ’¾ Sauvegarde locale de l'index FAISS...")
vectorstore.save_local("faiss_index")

# â€” Ã‰tape 7 : Test de recherche
query = "Ã©vÃ©nements de jazz Ã  Toulouse"
print(f"ğŸ” Recherche sÃ©mantique : {query}")
docs_retrieved = vectorstore.similarity_search(query, k=3)

for i, doc in enumerate(docs_retrieved, 1):
    print(f"\nğŸ”¸ RÃ©sultat {i}:")
    print(doc.page_content)
    print("ğŸ“ MÃ©tadonnÃ©es:", doc.metadata)
